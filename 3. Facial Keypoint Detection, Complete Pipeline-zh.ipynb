{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 人脸与人脸关键点检测\n",
    "\n",
    "在训练用于检测面部关键点的神经网络之后，你可以将此网络应用于包含人脸的*任何一个*图像。该神经网络需要一定大小的Tensor作为输入，因此，要检测任何一个人脸，你都首先必须进行一些预处理。\n",
    "\n",
    "1. 使用人脸检测器检测图像中的所有人脸。在这个notebook中，我们将使用Haar级联检测器。\n",
    "2. 对这些人脸图像进行预处理，使其成为灰度图像，并转换为你期望的输入尺寸的张量。这个步骤与你在Notebook 2中创建和应用的`data_transform` 类似，其作用是重新缩放、归一化，并将所有图像转换为Tensor，作为CNN的输入。\n",
    "3. 使用已被训练的模型检测图像上的人脸关键点。\n",
    "\n",
    "---\n",
    "\n",
    "在下一个python单元格中，我们要加载项目此部分所需的库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 选择图像 \n",
    "\n",
    "选择一张图像，执行人脸关键点检测。你可以在`images/`目录中选择任何一张人脸图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# load in color image for face detection\n",
    "image = cv2.imread('images/obamas.jpg')\n",
    "\n",
    "# switch red and blue color channels \n",
    "# --> by default OpenCV assumes BLUE comes first, not RED as in many images\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# plot the image\n",
    "fig = plt.figure(figsize=(9,9))\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检测该图像中的所有人脸\n",
    "\n",
    "要想检测到所选图像中的所有人脸，接下来，你要用到的是OpenCV预先训练的一个Haar级联分类器，所有这些分类器都可以在`detector_architectures/`目录中找到。\n",
    "\n",
    "在下面的代码中，我们要遍历原始图像中的每个人脸，并在原始图像的副本中的每个人脸上绘制一个红色正方形，而原始图像不需要修改。此外，你也可以 [新增一项眼睛检测 ](https://docs.opencv.org/3.4.1/d7/d8b/tutorial_py_face_detection.html) ，作为使用Haar检测器的一个可选练习。\n",
    "\n",
    "下面是各种图像上的人脸检测示例。\n",
    "\n",
    "<img src='images/haar_cascade_ex.png' width=80% height=80%/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in a haar cascade classifier for detecting frontal faces\n",
    "face_cascade = cv2.CascadeClassifier('detector_architectures/haarcascade_frontalface_default.xml')\n",
    "\n",
    "# run the detector\n",
    "# the output here is an array of detections; the corners of each detection box\n",
    "# if necessary, modify these parameters until you successfully identify every face in a given image\n",
    "faces = face_cascade.detectMultiScale(image, 1.2, 2)\n",
    "\n",
    "# make a copy of the original image to plot detections on\n",
    "image_with_detections = image.copy()\n",
    "\n",
    "# loop over the detected faces, mark the image where each face is found\n",
    "for (x,y,w,h) in faces:\n",
    "    # draw a rectangle around each detected face\n",
    "    # you may also need to change the width of the rectangle drawn depending on image resolution\n",
    "    cv2.rectangle(image_with_detections,(x,y),(x+w,y+h),(255,0,0),3) \n",
    "\n",
    "fig = plt.figure(figsize=(9,9))\n",
    "\n",
    "plt.imshow(image_with_detections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载到已训练的模型中\n",
    "\n",
    "有了一个可以使用的图像后（在这里，你可以选择`images/` 目录中的任何一张人脸图像），下一步是对该图像进行预处理并将其输入进CNN人脸关键点检测器。\n",
    "\n",
    "首先，按文件名加载你选定的最佳模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models import Net\n",
    "\n",
    "net = Net()\n",
    "\n",
    "## TODO: load the best saved model parameters (by your path name)\n",
    "## You'll need to un-comment the line below and add the correct name for *your* saved model\n",
    "# net.load_state_dict(torch.load('saved_models/keypoints_model_1.pt'))\n",
    "\n",
    "## print out your net and prepare it for testing (uncomment the line below)\n",
    "# net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 关键点检测\n",
    "\n",
    "现在，我们需要再一次遍历图像中每个检测到的人脸，只是这一次，你需要将这些人脸转换为CNN可以接受的张量形式的输入图像。\n",
    "\n",
    "### TODO: 将每个检测到的人脸转换为输入Tensor\n",
    "\n",
    "你需要对每个检测到的人脸执行以下操作：\n",
    "1. 将人脸从RGB图转换为灰度图\n",
    "2. 把灰度图像归一化，使其颜色范围落在[0,1]范围，而不是[0,255]\n",
    "3. 将检测到的人脸重新缩放为CNN的预期方形尺寸（我们建议为 224x224）\n",
    "4. 将numpy图像变形为torch图像。\n",
    "\n",
    "**提示**: Haar检测器检测到的人脸大小与神经网络训练过的人脸大小不同。如果你发现模型生成的关键点对给定的人脸来说，显得太小，请尝试在检测到的`roi`中添加一些填充，然后将其作为模型的输入。\n",
    "\n",
    "你可能会发现，参看`data_load.py`中的转换代码对帮助执行这些处理步骤很有帮助。\n",
    "\n",
    "\n",
    "### TODO: 检测并显示预测到的关键点\n",
    "\n",
    "将每个人脸适当地转换为网络的输入Tensor之后，就可以将`net` 应用于每个人脸。输出应该是预测到的人脸关键点，这些关键点需要“非归一化”才能显示。你可能会发现，编写一个类似`show_keypoints`的辅助函数会很有帮助。最后，你会得到一张如下的图像，其中人脸关键点与每张人脸上的面部特征非常匹配：\n",
    "\n",
    "<img src='images/michelle_detected.png' width=30% height=30%/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_copy = np.copy(image)\n",
    "\n",
    "# loop over the detected faces from your haar cascade\n",
    "for (x,y,w,h) in faces:\n",
    "    \n",
    "    # Select the region of interest that is the face in the image \n",
    "    roi = image_copy[y:y+h, x:x+w]\n",
    "    \n",
    "    ## TODO: Convert the face region from RGB to grayscale\n",
    "\n",
    "    ## TODO: Normalize the grayscale image so that its color range falls in [0,1] instead of [0,255]\n",
    "    \n",
    "    ## TODO: Rescale the detected face to be the expected square size for your CNN (224x224, suggested)\n",
    "    \n",
    "    ## TODO: Reshape the numpy image shape (H x W x C) into a torch image shape (C x H x W)\n",
    "    \n",
    "    ## TODO: Make facial keypoint predictions using your loaded, trained network \n",
    "\n",
    "    ## TODO: Display each detected face and the corresponding keypoints        \n",
    "        \n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
