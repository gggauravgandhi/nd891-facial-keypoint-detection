{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义卷积神经网络（CNN）\n",
    "\n",
    "查看正在使用的数据之后，了解图像与关键点的形状，接下来，就可以定义一个机器人可以从这些数据中 *学习*的卷积神经网络。\n",
    "\n",
    "在这个notebook和`models.py`中，你的任务是：\n",
    "1. 定义一个CNN，把图像作为输入，把关键点作为输出\n",
    "2. 与以前一样，构造转换后的FaceKeypointsDataset\n",
    "3. 使用训练数据训练这个CNN，并跟踪损失\n",
    "4. 查看训练模型对测试数据的执行情况\n",
    "5. 如有必要，请修改CNN结构并模拟超参数，使其*表现良好* **\\***\n",
    "\n",
    "**\\***  什么是*表现良好*？\n",
    "\n",
    "“表现良好”意味着该模型的损失在训练期间有所降低，**而且**该模型应用于测试图像数据时，会产生与每个人脸的真实关键点紧密匹配的关键点。你会在这个notebook中看到这个例子。\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## CNN架构\n",
    "\n",
    "回想一下，CNN是由下列几种类型的层定义的：\n",
    "* 卷积层\n",
    "* 最大池化层\n",
    "* 全连接层\n",
    "\n",
    "你需要使用上述层，而且我们建议你添加多个卷积层以及可能防止过度拟合的dropout层等。此外，你还可以查看一些有关关键点检测的文献，如 [这篇论文](https://arxiv.org/pdf/1710.00977.pdf)，帮助你确定该网络的结构。\n",
    "\n",
    "\n",
    "### TODO: 在`models.py`文件中定义你的模型\n",
    "\n",
    "此文件大部分为空，但其中包含预期的名称和一些用于创建模型的TODO事项。\n",
    "\n",
    "---\n",
    "\n",
    "## PyTorch神经网络\n",
    "\n",
    "要在PyTorch中定义神经网络，你可以在函数`__init__`中定义一个模型的各个层，并定义一个网络的前馈行为，该网络会在函数`forward`中使用这些初始化的层，而该函数会接收输入图像张量`x`。此Net类的结构如下所示，并由你来填充。\n",
    "\n",
    "注意：在训练期间，PyTorch能够通过跟踪网络的前馈行为并使用autograd来计算该网络中权重的更新来执行反向传播。\n",
    "\n",
    "#### 在` __init__`中定义层\n",
    "提醒一下，卷积层与池化层可以像这样来定义（在`__init__`中）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 input image channel (for grayscale images), 32 output channels/feature maps, 3x3 square convolution kernel\n",
    "self.conv1 = nn.Conv2d(1, 32, 3)\n",
    "\n",
    "# maxpool that uses a square window of kernel_size=2, stride=2\n",
    "self.pool = nn.MaxPool2d(2, 2)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 引用`forward`中的层\n",
    "然后在这样的`forward`函数中引用，其中卷积1层在应用最大池化之前应用了ReLu激活函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = self.pool(F.relu(self.conv1(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最佳做法是把权重将在训练过程中发生变化的任何层防治在`__init__`中，并在`forward`函数中引用它们。所有始终以相同方式运行的层或函数（例如预定义的激活函数）应*只* 出现在`forward` 函数中。\n",
    "\n",
    "#### 为什么要用models.py文件\n",
    "\n",
    "你的任务是在`models.py`文件中定义该网络，便于在此项目目录中的不同notebook中按名称保存和加载你定义的任何模型。例如，通过在`models.py`中定义名为`Net`的CNN类，通过简单地导入该类并实例化模型，就可以在此notebook和其他notebook中创建相同的体系结构："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    from models import Net\n",
    "    net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data if you need to; if you have already loaded the data, you may comment this cell out\n",
    "# -- DO NOT CHANGE THIS CELL -- #\n",
    "!mkdir /data\n",
    "!wget -P /data/ https://s3.amazonaws.com/video.udacity-data.com/topher/2018/May/5aea1b91_train-test-data/train-test-data.zip\n",
    "!unzip -n /data/train-test-data.zip -d /data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">**注意：**工作区会在持续30分钟的不活动状态后，自动关闭连接，包括训练时出现不活动状态。使用下面的代码段可以在训练期间保持工作区的活动状态。下面导入了active_session上下文管理器。\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workspace_utils import active_session\n",
    "\n",
    "with active_session():\n",
    "    train_model(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the usual resources\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# import utilities to keep workspaces alive during model training\n",
    "from workspace_utils import active_session\n",
    "\n",
    "# watch for any changes in model.py, if it changes, re-load it automatically\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Define the Net in models.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "## TODO: Once you've define the network, you can instantiate it\n",
    "# one example conv layer has been provided for you\n",
    "from models import Net\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 转换数据集 \n",
    "\n",
    "为训练做准备，你还需要创建一个图像和关键点的转换数据集。\n",
    "\n",
    "### TODO: 定义一个数据转换\n",
    "\n",
    "在PyTorch中，卷积神经网络需要一个大小一致的torch图像作为输入。为了进行有效的训练，以及在训练过程中该模型的损失不会放大，我们还建议你对输入图像和关键点进行归一化。必要的转换已在`data_load.py`中定义，你无需再做修改。另外，你可以看一下这个文件，你会在该文件中看到Notebook 1中定义和应用的相同转换。\n",
    "\n",
    "要定义下面的数据转换，请使用以下[组合](http://pytorch.org/tutorials/beginner/data_loading_tutorial.html#compose-transforms) ：\n",
    "1. 重新缩放和/或裁剪数据，最终需要一个方形图像（建议大小为224x224px）\n",
    "2. 归一化图像和关键点；将每个RGB图像转换为颜色范围为[0,1]的灰度图像，并将给定关键点转换为[-1,1]的范围\n",
    "3. 将这些图像和关键点转换为张量\n",
    "\n",
    "这些转换已在`data_load.py`中定义，但是否要在下面调用它们并创建一个`data_transform`，这都取决于你。**该转换将应用于训练数据，以及稍后的测试数据**。这样将改变显示这些图像和关键点的方式，但这些步骤对于高效训练来说非常重要。\n",
    "\n",
    "需要说明的一点是，如果你想要执行数据增强（在此项目中是可选的），并随机旋转或移动这些图像，方形图像大小将会很有用，将224x224图像旋转90度就会产生相同的输出形状。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "# the dataset we created in Notebook 1 is copied in the helper file `data_load.py`\n",
    "from data_load import FacialKeypointsDataset\n",
    "# the transforms we defined in Notebook 1 are in the helper file `data_load.py`\n",
    "from data_load import Rescale, RandomCrop, Normalize, ToTensor\n",
    "\n",
    "\n",
    "## TODO: define the data_transform using transforms.Compose([all tx's, . , .])\n",
    "# order matters! i.e. rescaling should come before a smaller crop\n",
    "data_transform = None\n",
    "\n",
    "# testing that you've defined a transform\n",
    "assert(data_transform is not None), 'Define a data_transform'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the transformed dataset\n",
    "transformed_dataset = FacialKeypointsDataset(csv_file='/data/training_frames_keypoints.csv',\n",
    "                                             root_dir='/data/training/',\n",
    "                                             transform=data_transform)\n",
    "\n",
    "\n",
    "print('Number of images: ', len(transformed_dataset))\n",
    "\n",
    "# iterate through the transformed dataset and print some stats about the first few samples\n",
    "for i in range(4):\n",
    "    sample = transformed_dataset[i]\n",
    "    print(i, sample['image'].size(), sample['keypoints'].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 批处理并加载数据\n",
    "\n",
    "定义了转换数据集之后，接下来，我们可以使用PyTorch的DataLoader类来批量加载任意大小的训练数据，也可以对训练模型的数据进行置乱处理。你可以在 [本文档](http://pytorch.org/docs/master/data.html)中阅读有关DataLoader参数的更多信息。\n",
    "\n",
    "#### 批量大小\n",
    "确定用于训练模型的最合适的批量是多少。小批量与大批量都要试一试，并注意在模型训练时损失会如何减少。批量过大可能会导致模型在训练时崩溃和/或内存不足。\n",
    "\n",
    "**Windows用户需要注意：**请将`num_workers`改为0，否则可能会遇到DataLoader失效的问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data in batches\n",
    "batch_size = 10\n",
    "\n",
    "train_loader = DataLoader(transformed_dataset, \n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True, \n",
    "                          num_workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练之前\n",
    "\n",
    "看一下这个模型在训练之前的表现。你应该会看到，它预测的关键点从一个点开始，并且与人脸上的关键点根本不匹配！你可以把此行为可视化，并在训练后将其与模型进行比较，还可以查看该模型是如何改进的。\n",
    "\n",
    "#### 加载测试数据集\n",
    "\n",
    "此模型之前*没有*见过这个测试数据集，这就是说，它没有使用这些图像进行过训练。在这里，我们将加载此测试数据，并在训练前后，查看你的模型在此数据集上的表现效果如何！\n",
    "\n",
    "为了可视化这些测试数据，我们必须要做一些非转换步骤，将图像转换为张量的python图像，并将关键点重新转换回可识别的范围。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the test data, using the dataset class\n",
    "# AND apply the data_transform you defined above\n",
    "\n",
    "# create the test dataset\n",
    "test_dataset = FacialKeypointsDataset(csv_file='/data/test_frames_keypoints.csv',\n",
    "                                             root_dir='/data/test/',\n",
    "                                             transform=data_transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data in batches\n",
    "batch_size = 10\n",
    "\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True, \n",
    "                          num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将模型应用于测试样本\n",
    "\n",
    "要在测试数据样本上测试模型，你必须执行以下步骤：\n",
    "1. 从样本中提取图像和实际真值关键点\n",
    "2. 将图像隐藏在变量中，便于你的网络将其作为输入处理，并跟踪图像在该网络中移动时发生的变化。\n",
    "3. 确保图像是模型所需的FloatTensor。\n",
    "4. 通过网络向前传递图像，获得预测的输出关键点。\n",
    "\n",
    "此函数测试的是该网络在第一批测试数据上的执行情况。它会返回图像、转换图像、预测由模型产生的关键点以及实际真值关键点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model on a batch of test images\n",
    "\n",
    "def net_sample_output():\n",
    "    \n",
    "    # iterate through the test dataset\n",
    "    for i, sample in enumerate(test_loader):\n",
    "        \n",
    "        # get sample data: images and ground truth keypoints\n",
    "        images = sample['image']\n",
    "        key_pts = sample['keypoints']\n",
    "\n",
    "        # convert images to FloatTensors\n",
    "        images = images.type(torch.FloatTensor)\n",
    "\n",
    "        # forward pass to get net output\n",
    "        output_pts = net(images)\n",
    "        \n",
    "        # reshape to batch_size x 68 x 2 pts\n",
    "        output_pts = output_pts.view(output_pts.size()[0], 68, -1)\n",
    "        \n",
    "        # break after first image is tested\n",
    "        if i == 0:\n",
    "            return images, output_pts, key_pts\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 调试技巧\n",
    "\n",
    "如果此处出现尺寸或维度错误，请确保你的网络输出预期数量的关键点！或者，如果收到Tensor类型的错误，请考虑将数据转换为float类型的上述代码进行更改，float类型为：`images = images.type(torch.FloatTensor)`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the above function\n",
    "# returns: test images, test predicted keypoints, test ground truth keypoints\n",
    "test_images, test_outputs, gt_pts = net_sample_output()\n",
    "\n",
    "# print out the dimensions of the data to see if they make sense\n",
    "print(test_images.data.size())\n",
    "print(test_outputs.data.size())\n",
    "print(gt_pts.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将预测的关键点可视化\n",
    "\n",
    "让模型生成一些预测的输出关键点之后，就可以用一种类似于我们之前显示这些数据的方式来显示这些点，只是这一次，要显示这些点，我们必须“取消转换”图像/关键点数据。\n",
    "\n",
    "请注意，我已经定义了一个*新*函数`show_all_keypoints`，它会显示灰度图像、其预测的关键点以及其实际真值关键点（如果提供的话）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_all_keypoints(image, predicted_key_pts, gt_pts=None):\n",
    "    \"\"\"Show image with predicted keypoints\"\"\"\n",
    "    # image is grayscale\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.scatter(predicted_key_pts[:, 0], predicted_key_pts[:, 1], s=20, marker='.', c='m')\n",
    "    # plot ground truth points as green pts\n",
    "    if gt_pts is not None:\n",
    "        plt.scatter(gt_pts[:, 0], gt_pts[:, 1], s=20, marker='.', c='g')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 非转换\n",
    "\n",
    "接下来，你会看到一个辅助函数，即`visualize_output`，它会接收一批图像、预测关键点以及实际真值关键点，并显示一组图像及其真实/预测关键点。\n",
    "\n",
    "此函数的主要作用是获取批量图像和关键点数据（CNN的输入和输出），并将它们转换为numpy图像和非归一化关键点（x，y），从而进行正常显示。非转换过程将关键点和图像转换为来自Tensors的numpy数组，*此外*， 它撤消了Normalize（）转换中完成的关键点归一化。但前提是我们假设，你在载测试数据时应用了这些转换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the output\n",
    "# by default this shows a batch of 10 images\n",
    "def visualize_output(test_images, test_outputs, gt_pts=None, batch_size=10):\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        plt.figure(figsize=(20,10))\n",
    "        ax = plt.subplot(1, batch_size, i+1)\n",
    "\n",
    "        # un-transform the image data\n",
    "        image = test_images[i].data   # get the image from it's Variable wrapper\n",
    "        image = image.numpy()   # convert to numpy array from a Tensor\n",
    "        image = np.transpose(image, (1, 2, 0))   # transpose to go from torch to numpy image\n",
    "\n",
    "        # un-transform the predicted key_pts data\n",
    "        predicted_key_pts = test_outputs[i].data\n",
    "        predicted_key_pts = predicted_key_pts.numpy()\n",
    "        # undo normalization of keypoints  \n",
    "        predicted_key_pts = predicted_key_pts*50.0+100\n",
    "        \n",
    "        # plot ground truth points for comparison, if they exist\n",
    "        ground_truth_pts = None\n",
    "        if gt_pts is not None:\n",
    "            ground_truth_pts = gt_pts[i]         \n",
    "            ground_truth_pts = ground_truth_pts*50.0+100\n",
    "        \n",
    "        # call show_all_keypoints\n",
    "        show_all_keypoints(np.squeeze(image), predicted_key_pts, ground_truth_pts)\n",
    "            \n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "# call it\n",
    "visualize_output(test_images, test_outputs, gt_pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练\n",
    "\n",
    "#### 损失函数\n",
    "训练一个用于预测关键点的网络与训练一个用于预测类的网络不同。你可能希望选择适合回归的损失函数，而不是输出类的分布并使用交交叉熵损失函数，因为损失函数可以用于直接比较预测值和目标值。有关各种损失函数（如MSE或L1 / SmoothL1损失），请阅读 [本文档](http://pytorch.org/docs/master/_modules/torch/nn/modules/loss.html)中的内容。\n",
    "\n",
    "### TODO: 定义损失与优化\n",
    "\n",
    "接下来，你需要通过定义损失函数和优化程序来定义模型的训练方式。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Define the loss and optimization\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = None\n",
    "\n",
    "optimizer = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练与初步观察\n",
    "\n",
    "现在，你要使用大量epoch，从`train_loader`中训练你的批量训练数据。\n",
    "\n",
    "为了快速观察你的模型是如何训练并决定是否应该修改它的结构或超参数，我们建议你最开始的时候使用一个或两个epoch。训练时，请注意观察模型的损失会如何随着时间的推移而变化：例如，它会先快速减少然后再减慢吗？或者起初会在一段时间后出现减少？如果更改了训练数据的批量大小或修改损失函数，会发生什么变化？\n",
    "\n",
    "在使用多个epoch进行训练并创建最终模型之前，使用这些初始观察值对模型进行更改并确定一个最佳架构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(n_epochs):\n",
    "\n",
    "    # prepare the net for training\n",
    "    net.train()\n",
    "\n",
    "    for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "        \n",
    "        running_loss = 0.0\n",
    "\n",
    "        # train on batches of data, assumes you already have train_loader\n",
    "        for batch_i, data in enumerate(train_loader):\n",
    "            # get the input images and their corresponding labels\n",
    "            images = data['image']\n",
    "            key_pts = data['keypoints']\n",
    "\n",
    "            # flatten pts\n",
    "            key_pts = key_pts.view(key_pts.size(0), -1)\n",
    "\n",
    "            # convert variables to floats for regression loss\n",
    "            key_pts = key_pts.type(torch.FloatTensor)\n",
    "            images = images.type(torch.FloatTensor)\n",
    "\n",
    "            # forward pass to get outputs\n",
    "            output_pts = net(images)\n",
    "\n",
    "            # calculate the loss between predicted and target keypoints\n",
    "            loss = criterion(output_pts, key_pts)\n",
    "\n",
    "            # zero the parameter (weight) gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # backward pass to calculate the weight gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # update the weights\n",
    "            optimizer.step()\n",
    "\n",
    "            # print loss statistics\n",
    "            running_loss += loss.item()\n",
    "            if batch_i % 10 == 9:    # print every 10 batches\n",
    "                print('Epoch: {}, Batch: {}, Avg. Loss: {}'.format(epoch + 1, batch_i+1, running_loss/10))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train your network\n",
    "n_epochs = 1 # start small, and increase when you've decided on your model structure and hyperparams\n",
    "\n",
    "# this is a Workspaces-specific context manager to keep the connection\n",
    "# alive while training your model, not part of pytorch\n",
    "with active_session():\n",
    "    train_net(n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试数据\n",
    "\n",
    "了解你的模型在之前未见过的测试数据上的表现如何。我们已经对测试数据进行加载与转换，这一点类似于与训练数据时的做法类似。接下来，在这些图像上运行已被训练的模型，查看其生成的关键点类型。你应该能够观察到你的模型是否拟合了它看到的每个新人脸，这些点是否是随机分布的，以及这些点实际上是否过度拟合了训练数据而没有进行归纳。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a sample of test data again\n",
    "test_images, test_outputs, gt_pts = net_sample_output()\n",
    "\n",
    "print(test_images.data.size())\n",
    "print(test_outputs.data.size())\n",
    "print(gt_pts.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: visualize your test output\n",
    "# you can use the same function as before, by un-commenting the line below:\n",
    "\n",
    "# visualize_output(test_images, test_outputs, gt_pts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "找到了一个或两个表现良好的模型后，保存你的模型，这样你就可以加载它并在以后使用它了！\n",
    "\n",
    "在这里，你需要保存模型，但请**在提交项目之前删除任何检查点和已保存的模型**，否则你的工作区可能会因为太大而无法提交。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: change the name to something uniqe for each new model\n",
    "model_dir = 'saved_models/'\n",
    "model_name = 'keypoints_model_1.pt'\n",
    "\n",
    "# after training, save your model parameters in the dir 'saved_models'\n",
    "torch.save(net.state_dict(), model_dir+model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完成对一个表现良好的模型的训练后，请回答以下问题，以便我们对你的训练和架构选择过程有一些了解。要通过此项目，你需要回答下列所有问题。\n",
    "\n",
    "### 问题1：你选择了哪些优化和损失函数？为什么会这样选择？\n",
    "\n",
    "\n",
    "**答案**: 请在这里写下你的答案（双击即可编辑这个单元格）\n",
    "\n",
    "### 问题2：最开始，你的网络架构是什么样的？在尝试不同的架构时，又做了怎样的修改？为避免过度拟合数据，你是否决定添加了更多卷积层或其他层？\n",
    "\n",
    "**答案**: 请在这里写下你的答案\n",
    "\n",
    "### 问题3：你是如何决定训练模型的epoch数量和batch_size的？\n",
    "\n",
    "**答案**: 请在这里写下你的答案\n",
    "\n",
    "## 特征可视化\n",
    "\n",
    "有时，神经网络会被当做是一个黑盒子，给定一些输入，它就会学习产生一些输出。 事实上，CNN正在学习识别各种空间模式，你可以通过查看构成每个卷积核的权重并将这些一次性应用于样本图像来可视化每个卷积层已被训练识别的内容。这种技术称为特征可视化，它对于理解CNN的内部工作方式很有帮助。\n",
    "\n",
    "在下面的单元格中，你可以看到如何从第一个卷积层中按索引提取单个滤波器。滤波器应显示为灰度网格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the weights in the first conv layer, \"conv1\"\n",
    "# if necessary, change this to reflect the name of your first conv layer\n",
    "weights1 = net.conv1.weight.data\n",
    "\n",
    "w = weights1.numpy()\n",
    "\n",
    "filter_index = 0\n",
    "\n",
    "print(w[filter_index][0])\n",
    "print(w[filter_index][0].shape)\n",
    "\n",
    "# display the filter weights\n",
    "plt.imshow(w[filter_index][0], cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征映射\n",
    "\n",
    "每个CNN至少包含一个由堆叠滤波器（也称为卷积核）组成的卷积层。CNN在进行训练时，它要学习在卷积内核中包含哪些权重，当这些内核应用于某些输入图像时，它们会产生一组**特征映射**。因此，特征映射只是过滤图像的集合，它们是通过将卷积核应用于输入图像而产生的图像。这些映射向我们展示了神经网络不同层学习提取的特征。例如，你可以想象一个卷积内核，它可以检测到脸部的垂直边缘，而另一个可以检测到眼角的边缘。通过将这些内核应用于图像，你可以看到每个内核检测到了哪些特征。具体请看以下示例，从它在图像中显示线条的方式，你可以将其表征为边缘检测滤波。\n",
    "\n",
    "<img src='images/feature_map_ex.png' width=50% height=50%/>\n",
    "\n",
    "\n",
    "接下来，选择一个测试图像并使用已被训练的CNN中的一个卷积内核对其进行过滤。查看过滤后的输出，了解该内核检测到的内容。\n",
    "\n",
    "### TODO: 过滤图像，查看卷积内核的效果\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO: load in and display any image from the transformed test dataset\n",
    "\n",
    "## TODO: Using cv's filter2D function,\n",
    "## apply a specific set of filter weights (like the one displayed above) to the test image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题4：从已被训练的CNN中选择一个滤波器并将其应用于测试图像。你认为它会起到什么作用？你认为它会检测到哪种特征？\n",
    "\n",
    "\n",
    "**答案**:它检测到的是垂直线条还是模糊噪音等？请在这里写下你的答案\n",
    "\n",
    "---\n",
    "## 继续加油吧！\n",
    "\n",
    "现在，你已经定义并训练了模型，最终也保存了一个最佳模型。接下来，就是最后一个notebook，它会将人脸检测器与你保存的模型相结合，创建一个人脸关键点检测系统，用于预测一种图像中*任何一个* 人脸的关键点！"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
