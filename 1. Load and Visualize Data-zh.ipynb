{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 人脸关键点检测\n",
    "\n",
    "该项目是关于定义和训练用于执行人脸关键点检测的卷积神经网络，并使用计算机视觉技术来转换人脸图像。你要做的第一步是加载和可视化将使用的数据。\n",
    "\n",
    "首先，我们来看一些图像和相应的人脸关键点示例。\n",
    "\n",
    "<img src='images/key_pts_example.png' width=50% height=50%/>\n",
    "\n",
    "人脸关键点（也称为人脸特征点）指的是上面的图像中，每个人脸上显示的洋红色的小点。在每个训练和测试图像中，有一个人脸和**68 个关键点，其中，人脸的坐标是 (x, y)**。这些关键点标记了人脸的重要区域：眼睛，嘴角，鼻子等。这些关键点与许多应用相关，如人脸滤波、情感识别、姿势识别等。在这里，它们是编号的，你可以看到特定范围的点与该人脸的不同部分相匹配。\n",
    "\n",
    "<img src='images/landmarks_numbered.jpg' width=30% height=30%/>\n",
    "\n",
    "---\n",
    "\n",
    "## 加载和可视化数据\n",
    "\n",
    "使用任何数据集的第一步，都是要熟悉你的数据。此外，你还需要加载人脸及其关键点的图像并将其可视化！这组图像数据是从[YouTube 人脸数据集](https://www.cs.tau.ac.il/~wolf/ytfaces/)中提取的，其中包含YouTube视频中的人物视频。这些视频通过一些处理步骤进行输入，并转换为包含一个人脸和相关关键点的图像帧集。\n",
    "\n",
    "#### 训练数据和测试数据\n",
    "\n",
    "该人脸关键点数据集由5770张彩色图像组成。所有这些图像都被分成训练数据集与测试数据集。\n",
    "\n",
    "* 这些图像中有3462张个是训练图像，供你在创建用来预测关键点的模型时使用。\n",
    "* 另外2308张是测试图像，用于测试该模型的准确性。\n",
    "\n",
    "有关此数据集中图像和关键点的信息汇总在CSV文件中，我们可以使用`pandas`读取这些文件。接下来，我们要读取训练CSV并在（N，2）数组中获取注释，其中N是关键点的数量，2是关键点坐标（x，y）的维度。\n",
    "\n",
    "---\n",
    "\n",
    "首先，在着手行动之前，我们必须要加载图像数据。这些数据存储在一个压缩文件中。在下面的单元格中，我们可以通过它的URL访问该压缩文件，并将数据解压缩到与工作区Home目录分开的`/data/`目录中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- DO NOT CHANGE THIS CELL -- #\n",
    "!mkdir /data\n",
    "!wget -P /data/ https://s3.amazonaws.com/video.udacity-data.com/topher/2018/May/5aea1b91_train-test-data/train-test-data.zip\n",
    "!unzip -n /data/train-test-data.zip -d /data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，加载训练数据，并显示有关该数据的一些统计数据，最后要确保它已正确加载！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_pts_frame = pd.read_csv('/data/training_frames_keypoints.csv')\n",
    "\n",
    "n = 0\n",
    "image_name = key_pts_frame.iloc[n, 0]\n",
    "key_pts = key_pts_frame.iloc[n, 1:].as_matrix()\n",
    "key_pts = key_pts.astype('float').reshape(-1, 2)\n",
    "\n",
    "print('Image name: ', image_name)\n",
    "print('Landmarks shape: ', key_pts.shape)\n",
    "print('First 4 key pts: {}'.format(key_pts[:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out some stats about the data\n",
    "print('Number of images: ', key_pts_frame.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 观察一些图像\n",
    "\n",
    "下面是一个`show_keypoints`函数，它用于接收一张图像和关键点并将它们显示出来。查看此数据时，**请注意这些图像的尺寸不同，**人脸也不同！为了最终使用这些图像训练神经网络，我们需要标准化它们的形状。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_keypoints(image, key_pts):\n",
    "    \"\"\"Show image with keypoints\"\"\"\n",
    "    plt.imshow(image)\n",
    "    plt.scatter(key_pts[:, 0], key_pts[:, 1], s=20, marker='.', c='m')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a few different types of images by changing the index n\n",
    "\n",
    "# select an image by index in our data frame\n",
    "n = 0\n",
    "image_name = key_pts_frame.iloc[n, 0]\n",
    "key_pts = key_pts_frame.iloc[n, 1:].as_matrix()\n",
    "key_pts = key_pts.astype('float').reshape(-1, 2)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "show_keypoints(mpimg.imread(os.path.join('/data/training/', image_name)), key_pts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset类与转换\n",
    "\n",
    "为了准备训练我们的数据，我们要使用PyTorch的Dataset类。这段代码大部分都是[PyTorch 数据加载教程](http://pytorch.org/tutorials/beginner/data_loading_tutorial.html)中代码的修改版。\n",
    "\n",
    "#### Dataset类\n",
    "\n",
    "``torch.utils.data.Dataset``是一个表示数据集的抽象类。这个类可以让我们加载批量的图像/关键点数据，并统一地将转换应用于我们的数据，例如，为了训练神经网络，重新缩放和归一化化图像。\n",
    "\n",
    "\n",
    "你的自定义数据集应继承``Dataset``并覆盖以下方法：\n",
    "\n",
    "-  ``__len__`` ，从而使``len(dataset)``返回数据集的大小。\n",
    "\n",
    "-  ``__getitem__`` ，用于支持索引，使``dataset[i]`` 可\n",
    "     用于获取第i个图像/关键点数据样本。\n",
    "\n",
    "接下来，让我们为人脸关键点数据集创建一个dataset类。我们要读取``__init__``中的CSV文件，但将图像的读取留给``__getitem__``。这就是高效存储，因为所有图像都不是一次性存储在内存中，而是根据需要读取。\n",
    "\n",
    "我们的数据集示例将是一个字典``{'image': image, 'keypoints': key_pts}``。该数据集将采用可选参数``transform``，这样的话，任何所需的处理都可以应用于样本。在下一部分，我们要学习的是``transform``的有效性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class FacialKeypointsDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.key_pts_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.key_pts_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = os.path.join(self.root_dir,\n",
    "                                self.key_pts_frame.iloc[idx, 0])\n",
    "        \n",
    "        image = mpimg.imread(image_name)\n",
    "        \n",
    "        # if image has an alpha color channel, get rid of it\n",
    "        if(image.shape[2] == 4):\n",
    "            image = image[:,:,0:3]\n",
    "        \n",
    "        key_pts = self.key_pts_frame.iloc[idx, 1:].as_matrix()\n",
    "        key_pts = key_pts.astype('float').reshape(-1, 2)\n",
    "        sample = {'image': image, 'keypoints': key_pts}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，我们已经定义了这个类，接下来，我们要做的是实例化该数据集并显示一些图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the dataset\n",
    "face_dataset = FacialKeypointsDataset(csv_file='/data/training_frames_keypoints.csv',\n",
    "                                      root_dir='/data/training/')\n",
    "\n",
    "# print some stats about the dataset\n",
    "print('Length of dataset: ', len(face_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a few of the images from the dataset\n",
    "num_to_display = 3\n",
    "\n",
    "for i in range(num_to_display):\n",
    "    \n",
    "    # define the size of images\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    \n",
    "    # randomly select a sample\n",
    "    rand_i = np.random.randint(0, len(face_dataset))\n",
    "    sample = face_dataset[rand_i]\n",
    "\n",
    "    # print the shape of the image and keypoints\n",
    "    print(i, sample['image'].shape, sample['keypoints'].shape)\n",
    "\n",
    "    ax = plt.subplot(1, num_to_display, i + 1)\n",
    "    ax.set_title('Sample #{}'.format(i))\n",
    "    \n",
    "    # Using the same display function, defined earlier\n",
    "    show_keypoints(sample['image'], sample['keypoints'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 转换\n",
    "\n",
    "现在，上面的图像尺寸不同，但是，神经网络通常期望的是标准化的图像。因此，我们需要固定的尺寸、颜色范围和坐标的标准化范围。对于PyTorch来说，还需要把numpy列表和数组转换为Tensors。\n",
    "\n",
    "因此，我们需要编写一些预处理代码。\n",
    "下面，创建四个转换：\n",
    "\n",
    "-  ``Normalize``: 将彩色图像转换为范围为[0,1]的灰度值，并将关键点标准化为约[-1,1]的范围\n",
    "-  ``Rescale``: 将图像重新缩放到所需尺寸。\n",
    "-  ``RandomCrop``: 随机裁剪图像。\n",
    "-  ``ToTensor``: 将numpy图像转换为torch图像。\n",
    "\n",
    "\n",
    "我们将它们编写为可调用类而不是简单函数，这样，每次调用时都不需要传递转换的参数。 为此，我们只需要实现 ``__call__`` 方法就可以了。如果我们需要传入参数，还需要实现``__init__``方法。 我们可以使用类似下面的转换："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = Transform(params)\n",
    "transformed_sample = tx(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请注意以下这些转换通常是如何应用于图像及其关键点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, utils\n",
    "# tranforms\n",
    "\n",
    "class Normalize(object):\n",
    "    \"\"\"Convert a color image to grayscale and normalize the color range to [0,1].\"\"\"        \n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, key_pts = sample['image'], sample['keypoints']\n",
    "        \n",
    "        image_copy = np.copy(image)\n",
    "        key_pts_copy = np.copy(key_pts)\n",
    "\n",
    "        # convert image to grayscale\n",
    "        image_copy = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        # scale color range from [0, 255] to [0, 1]\n",
    "        image_copy=  image_copy/255.0\n",
    "        \n",
    "        # scale keypoints to be centered around 0 with a range of [-1, 1]\n",
    "        # mean = 100, sqrt = 50, so, pts should be (pts - 100)/50\n",
    "        key_pts_copy = (key_pts_copy - 100)/50.0\n",
    "\n",
    "\n",
    "        return {'image': image_copy, 'keypoints': key_pts_copy}\n",
    "\n",
    "\n",
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, key_pts = sample['image'], sample['keypoints']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = cv2.resize(image, (new_w, new_h))\n",
    "        \n",
    "        # scale the pts, too\n",
    "        key_pts = key_pts * [new_w / w, new_h / h]\n",
    "\n",
    "        return {'image': img, 'keypoints': key_pts}\n",
    "\n",
    "\n",
    "class RandomCrop(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, key_pts = sample['image'], sample['keypoints']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "\n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "\n",
    "        image = image[top: top + new_h,\n",
    "                      left: left + new_w]\n",
    "\n",
    "        key_pts = key_pts - [left, top]\n",
    "\n",
    "        return {'image': image, 'keypoints': key_pts}\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, key_pts = sample['image'], sample['keypoints']\n",
    "         \n",
    "        # if image has no grayscale color channel, add one\n",
    "        if(len(image.shape) == 2):\n",
    "            # add that third color dim\n",
    "            image = image.reshape(image.shape[0], image.shape[1], 1)\n",
    "            \n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        \n",
    "        return {'image': torch.from_numpy(image),\n",
    "                'keypoints': torch.from_numpy(key_pts)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试转换\n",
    "\n",
    "接下来，需要对这些转换进行测试，确保它们按预期运行。查看每个转换时，请注意，在这里，**顺序非常重要**。例如，你不能用一个小于原始图像的值来裁剪图像，而且原始图像的尺寸会有所不同。但是，如果首先选择重新缩放原始图像，则可以将其裁剪为小于重新缩放尺寸的任何尺寸。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test out some of these transforms\n",
    "rescale = Rescale(100)\n",
    "crop = RandomCrop(50)\n",
    "composed = transforms.Compose([Rescale(250),\n",
    "                               RandomCrop(224)])\n",
    "\n",
    "# apply the transforms to a sample image\n",
    "test_num = 500\n",
    "sample = face_dataset[test_num]\n",
    "\n",
    "fig = plt.figure()\n",
    "for i, tx in enumerate([rescale, crop, composed]):\n",
    "    transformed_sample = tx(sample)\n",
    "\n",
    "    ax = plt.subplot(1, 3, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title(type(tx).__name__)\n",
    "    show_keypoints(transformed_sample['image'], transformed_sample['keypoints'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建转换后的数据集\n",
    "\n",
    "下面，我们需要使用转换获取相同形状的灰度图像。通过输出结果数据的形状来验证转换的工作原理（输出的几个示例应该显示出一致的张量大小）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the data tranform\n",
    "# order matters! i.e. rescaling should come before a smaller crop\n",
    "data_transform = transforms.Compose([Rescale(250),\n",
    "                                     RandomCrop(224),\n",
    "                                     Normalize(),\n",
    "                                     ToTensor()])\n",
    "\n",
    "# create the transformed dataset\n",
    "transformed_dataset = FacialKeypointsDataset(csv_file='/data/training_frames_keypoints.csv',\n",
    "                                             root_dir='/data/training/',\n",
    "                                             transform=data_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some stats about the transformed data\n",
    "print('Number of images: ', len(transformed_dataset))\n",
    "\n",
    "# make sure the sample tensors are the expected size\n",
    "for i in range(5):\n",
    "    sample = transformed_dataset[i]\n",
    "    print(i, sample['image'].size(), sample['keypoints'].size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据迭代与批处理\n",
    "\n",
    "现在，我们使用``for``循环迭代这些数据，但是我们错过了很多PyTorch的数据集功能，特别是下列这些功能：\n",
    "\n",
    "-  批量处理数据\n",
    "-  置乱数据\n",
    "-  使用``multiprocessing``工作程序并行加载数据。\n",
    "\n",
    "而``torch.utils.data.DataLoader``是一个提供所有这些功能的迭代器。在*下一个*notebook中，需要批量加载数据来训练神经网络时，我们就会看到这个它的这个作用！\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "## 准备训练你的神经网络吧！\n",
    "\n",
    "到目前为止，你已经了解了如何加载与转换数据，也为构建一个用于训练这些数据的神经网络做好了准备。\n",
    "\n",
    "在下一个notebook中，你的任务是创建一个用于人脸关键点检测的CNN。"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
